{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bd6160-b514-48a4-bfcf-0bdbac77b6b4",
   "metadata": {},
   "source": [
    "# 🍜 頑固ラーメン屋のAIを作ろう (Build a Stubborn Ramen AI)\n",
    "\n",
    "---\n",
    "```text\n",
    " FFFFF   A   QQQQ      BBBB   OOO  TTTTT\n",
    " F      A A  Q  Q      B  B  O   O   T\n",
    " FFF   AAAAA Q  Q      BBBB  O   O   T\n",
    " F     A   A Q  Q      B  B  O   O   T\n",
    " F     A   A  QQ Q     BBBB   OOO    T\n",
    "```\n",
    "#  「初めての言語モデル構築」ラボへようこそ！\n",
    "---\n",
    "このワークショップでは、Pythonを使って **頑固なラーメン屋の店長** のようなAIをゼロから作ります。\n",
    "最初は何も知らないAIですが、学習（トレーニング）させることで、ラーメン屋らしい会話ができるようになります。\n",
    "\n",
    "# 📖 今日の辞書 (Concept Dictionary)\n",
    "難しい言葉が出てきたら、ここを見てください。\n",
    "\n",
    "| 言葉 (Term) | 意味 (Meaning) | 例え (Analogy) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Tokens (トークン)** | AIが読む文字の単位 | 「あ」「い」「う」など、文字ひとつひとつ |\n",
    "| **Batch Size (バッチサイズ)** | 一度に勉強する量 | 英単語カードを「5枚ずつ」めくるか、「30枚ずつ」めくるか |\n",
    "| **Loss (ロス・損失)** | AIの間違いの数 | テストの「バツ」の数。**0に近いほど賢い！** |\n",
    "| **Optimizer (オプティマイザ)** | AIを修正する先生 | 「そこ間違ってるよ、こう直しなさい」と指導する役割 |\n",
    "| **Iteration (イテレーション)** | 学習の回数 | ドリルを繰り返す回数 |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60f013-e12f-4d30-a410-3f8e340de80d",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ パート０：ライブラリの読み込み\n",
    "# ==============================================================================\n",
    " ニューラルネットワークの構築にはPyTorchを、UIにはipywidgetsを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898fa996-a29e-48c8-a697-7b8b971f78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Filter out the specific warning about pynvml\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997683c-4505-4c98-9069-be1af70b8703",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ パート1：教科書（データ）の準備\n",
    "# ==============================================================================\n",
    "\n",
    "AIに読ませる「頑固ラーメン屋の会話集」です。\n",
    "AIはこのテキストのパターンを真似するように学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643b1bc1-3d3b-40e4-b44a-31720921814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データの文字数: 31500 文字\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "客：いらっしゃい。\n",
    "店：へい、いらっしゃい。食券買ってな。\n",
    "客：おすすめは何ですか？\n",
    "店：うちは塩ラーメンしか置いてないよ。メニューをよく見なさい。\n",
    "客：すいません、お水ください。\n",
    "店：水はセルフサービスだよ。あそこの給水機を使ってくれ。\n",
    "客：大盛りはできますか？\n",
    "店：うちは大盛りやってないんだ。味のバランスが崩れるからね。\n",
    "客：麺の硬さは選べますか？\n",
    "店：うちは「普通」が一番うまいんだ。黙って座って待ってな。\n",
    "客：ごちそうさまでした。\n",
    "店：おう、まいど。丼はカウンターに上げてってな。\n",
    "客：トイレはどこですか？\n",
    "店：店の外を出て右だよ。\n",
    "客：替え玉お願いします。\n",
    "店：だから、メニュー見てくれよ。替え玉もやってないんだ。\n",
    "\"\"\" * 100  # データ量を増やすために100回繰り返します\n",
    "\n",
    "print(f\"データの文字数: {len(text)} 文字\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20c3b61-3698-4ec6-8c1d-6679ec2ed8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使われている文字の種類: 104 種類\n",
      "文字リスト: \n",
      "、。「」あいうえおかがきくげこごさしすせそただちってでどなにねのはへべまめもゃやよらりるれをんイウカサスセタトニバビフメュラルレンー一上丼何使出券右味塩外大客崩店座待普替機水玉番盛硬給置見買通選願食麺黙：？\n",
      "\n",
      "--- 変換テスト ---\n",
      "元の言葉: おすすめ\n",
      "AIの視点: [9, 19, 19, 37]\n"
     ]
    }
   ],
   "source": [
    "### ------------------------------------------------------------------------------\n",
    "### ここで「文字」を「数字」に変換します (AIは計算しかできないため)\n",
    "### ------------------------------------------------------------------------------\n",
    "\n",
    "### データの中にどんな文字があるかリストアップします\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"使われている文字の種類: {len(chars)} 種類\")\n",
    "print(f\"文字リスト: {''.join(chars)}\")\n",
    "\n",
    "### 文字と数字の対応表を作ります (Encoding / Decoding)\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]          # 文字 -> 数字\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # 数字 -> 文字\n",
    "\n",
    "print(\"\\n--- 変換テスト ---\")\n",
    "print(f\"元の言葉: おすすめ\")\n",
    "print(f\"AIの視点: {encode('おすすめ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30a12e-eb24-4fe3-9d01-8ee8f0842c18",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ パート2：AIの「脳」を構築する \n",
    "# ※ このセルは変更しなくてOKです。実行(Shift+Enter)だけしてください。\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6cbf26-8e64-41c3-9142-be94a934da52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIの脳の「設計図」が完成しました！\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # 各トークン（文字）の確率を読むためのテーブルを作成\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # 予測(logits)と正解(targets)を比べて、誤差(loss)を計算する\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # 現在の文字から、次の文字を予測して生成するループ\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "# データをバッチ（小分け）にする関数\n",
    "def get_batch(split):\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "    ix = torch.randint(len(data) - 8, (32,))\n",
    "    x = torch.stack([data[i:i+8] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+8+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "print(\"AIの脳の「設計図」が完成しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d79d8-db5b-49a6-97e2-030e770210b3",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 🔧 パート3：AIのトレーニング (★ ここが今日の主役です！) \n",
    "# ==============================================================================\n",
    "\n",
    "ここから皆さんの出番です。\n",
    "以下のコードには **空欄（______）** があります。\n",
    "ヒントを読みながら、正しいコードや数字を入れてAIを学習させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff00ed2-4521-4184-aa60-8719cf171b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "例：ラーメン屋のデータの「入力」と「正解」の関係\n",
      "\n",
      "ステップ 1:\n",
      "  AIが見ている文字 (Input):  'だ'\n",
      "  AIが当てるべき文字 (Target): 'よ'\n",
      "-------------------------\n",
      "ステップ 2:\n",
      "  AIが見ている文字 (Input):  'よ'\n",
      "  AIが当てるべき文字 (Target): '。'\n",
      "-------------------------\n",
      "ステップ 3:\n",
      "  AIが見ている文字 (Input):  '。'\n",
      "  AIが当てるべき文字 (Target): '\n",
      "'\n",
      "-------------------------\n",
      "ステップ 4:\n",
      "  AIが見ている文字 (Input):  '\n",
      "'\n",
      "  AIが当てるべき文字 (Target): '客'\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 🧐 先生用の解説コーナー (Instructor Demo)\n",
    "# AIが何を「正解」としているか確認しましょう\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "x_demo, y_demo = get_batch('train')\n",
    "\n",
    "print(\"例：ラーメン屋のデータの「入力」と「正解」の関係\\n\")\n",
    "\n",
    "# 最初のバッチの、最初の4文字だけを見てみます\n",
    "for i in range(4):\n",
    "    input_text = decode([x_demo[0, i].item()])\n",
    "    target_text = decode([y_demo[0, i].item()])\n",
    "    \n",
    "    print(f\"ステップ {i+1}:\")\n",
    "    print(f\"  AIが見ている文字 (Input):  '{input_text}'\")\n",
    "    print(f\"  AIが当てるべき文字 (Target): '{target_text}'\")\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d622bbc6-8b62-48d2-bf01-de79533ca9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000回の学習を開始します...\n",
      "回数: 0, 誤差(Loss): 5.2975\n",
      "回数: 500, 誤差(Loss): 4.5356\n",
      "回数: 1000, 誤差(Loss): 3.7590\n",
      "回数: 1500, 誤差(Loss): 3.2295\n",
      "回数: 2000, 誤差(Loss): 2.5521\n",
      "回数: 2500, 誤差(Loss): 2.0761\n",
      "学習完了！\n"
     ]
    }
   ],
   "source": [
    "# モデルを初期化します\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 実験コーナー：パラメータを設定しよう (Fill in the blanks!)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# 学習回数 (AIがドリルを解く回数)\n",
    "# ヒント: 100回だと全然足りませんが、3000回やると少し賢くなります。\n",
    "# 推奨: 最初は 100 で試して、後で 3000 に書き換えてみましょう。\n",
    "max_iters = 3000 \n",
    "\n",
    "\n",
    "print(f\"{max_iters}回の学習を開始します...\")\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # データを取得\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # クイズ：学習ループを完成させよう (ヒントを見て選んでください)\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # 1. 誤差(Loss)を計算する\n",
    "    logits, loss = model(xb, yb)\n",
    "    \n",
    "    # 2. 前回の計算の「ゴミ」を掃除する呪文\n",
    "    # ヒント: [ 選択肢: optimizer.zero_grad(set_to_none=True)  または  print(\"hello\") ]\n",
    "    # -------------------------------------------------------------\n",
    "    optimizer.zero_grad(set_to_none=True) \n",
    "\n",
    "    # 3. バックプロパゲーション (間違いの原因を探る)\n",
    "    loss.backward()\n",
    "    \n",
    "    # 4. パラメータを実際に更新する（先生が修正する）呪文\n",
    "    # ヒント: [ 選択肢: optimizer.step()  または  optimizer.stop() ]\n",
    "    # -------------------------------------------------------------\n",
    "    optimizer.step() \n",
    "\n",
    "    if iter % 500 == 0:\n",
    "        print(f\"回数: {iter}, 誤差(Loss): {loss.item():.4f}\")\n",
    "\n",
    "print(\"学習完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3b07f-2af0-425f-906f-0a42acbfb072",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ パート4：AI店長と話してみよう\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c124ee29-62cb-4efa-89ca-99ea2df0e835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AI店長の生成テキスト ---\n",
      "\n",
      "店の給盛め番きごでき通」機を使っラま黙だ。食水た玉カウ券トイごちメビ番こでは塩ラーーりやてくれる塩ね。食」めメン上りやかやしゃ待食ゃて待べ硬さいせ替うビまごってないん客：大盛げ置いを使ね店あそ機を番出\n",
      "店の給水選の給ごューに番サどこで買外ですかよくれ？\n",
      "客ね硬で。替え外？\n",
      "がトだ。のごう、上く」が崩店：玉塩へフく見て座せん客へ盛普が崩て大るたう崩ってな。\n",
      "「普使ってってなあそうませんルフサき麺普ル番味の給そうさませよ通せん「外ラおを願く見な。をよ黙機べまーーメンしか？使バ使願いっ番待塩へ：水機通」が崩あそこ右黙っし何し何ューにね機あすめーべまいせんえ外右まですを外客へいん客味へ見さいせきまいよ\n"
     ]
    }
   ],
   "source": [
    "print(\"--- AI店長の生成テキスト ---\")\n",
    "\n",
    "# 何もない状態(0)からスタートして、300文字生成させます\n",
    "context = torch.zeros((1, 1), dtype=torch.long)\n",
    "generated_output = model.generate(context, max_new_tokens=300)[0].tolist()\n",
    "\n",
    "# 数字を文字に戻して表示\n",
    "print(decode(generated_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be52ba9-4470-4c89-8389-d0b69b08ee62",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 🎮 パート5：リアルタイムで会話してみよう (Interactive Chat)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "178b620b-85d5-4e75-a8db-86834912436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI店長と会話できます。「終了」と打つと終わります。\n",
      "コツ: 「客：」から書き始めると、AIが「店：」と答えやすくなります。\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "入力してください (例: 客：おすすめは？) >>  終了\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def chat_with_ai(start_text):\n",
    "    # 1. ユーザーの入力を数字(トークン)に変換\n",
    "    try:\n",
    "        context = torch.tensor([encode(start_text)], dtype=torch.long)\n",
    "    except KeyError:\n",
    "        print(\"エラー: 学習データにない文字が含まれています。\")\n",
    "        return\n",
    "\n",
    "    # 2. AIに続きを書かせる (50文字くらい)\n",
    "    print(f\"あなた: {start_text}\", end=\"\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # 生成開始\n",
    "    generated_indices = model.generate(context, max_new_tokens=50)[0].tolist()\n",
    "    \n",
    "    # 3. 数字を文字に戻す (入力した部分はカットして、AIの生成部分だけ表示)\n",
    "    full_text = decode(generated_indices)\n",
    "    ai_response = full_text[len(start_text):] # 入力部分を削除\n",
    "    \n",
    "    print(f\"AI店長: {ai_response}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 会話ループ\n",
    "print(\"AI店長と会話できます。「終了」と打つと終わります。\")\n",
    "print(\"コツ: 「客：」から書き始めると、AIが「店：」と答えやすくなります。\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"入力してください (例: 客：おすすめは？) >> \")\n",
    "    if user_input == \"終了\":\n",
    "        break\n",
    "    \n",
    "    # 会話を実行\n",
    "    chat_with_ai(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c41f71-94d3-469b-953c-46ab01306830",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "# 🆘 お助けコーナー (Rescue Cell / Answer Key)\n",
    "\n",
    "もしエラーが出て動かなくなっても大丈夫です！\n",
    "下のコードは**正解**です。コピーして「パート3」のセルに貼り付けてください。\n",
    "\n",
    "```python\n",
    "# 🆘 正解コード (Answer Key)\n",
    "\n",
    "# 設定\n",
    "max_iters = 3000  # 学習回数は多いほうが賢くなります\n",
    "\n",
    "print(f\"{max_iters}回の学習を開始します...\")\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # 1. 誤差計算\n",
    "    logits, loss = model(xb, yb)\n",
    "    \n",
    "    # 2. 掃除 (答え: optimizer.zero_grad)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # 3. 逆伝播\n",
    "    loss.backward()\n",
    "    \n",
    "    # 4. 更新 (答え: optimizer.step)\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % 500 == 0:\n",
    "        print(f\"回数: {iter}, 誤差(Loss): {loss.item():.4f}\")\n",
    "\n",
    "print(\"学習完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3572e71-badb-4414-a48f-0ad35b5dc4b2",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# 🎉 午前の部：終了！ (Morning Session Complete)\n",
    "\n",
    "お疲れ様でした！これで「初めての言語モデル」の構築は完了です。\n",
    "\n",
    "### ✅ 午前中に学んだこと (Key Takeaways)\n",
    "1.  **AIは魔法ではない**: 巨大な「確率の計算機」であり、次に来る文字を予測しているだけです。\n",
    "2.  **学習のサイクル**: `予測` → `間違い(Loss)を計算` → `修正(Optimizer)` を何千回も繰り返すことで賢くなります。\n",
    "3.  **Loss (損失)**: この数字が下がれば下がるほど、AIはラーメン屋の口調を真似できるようになりました。\n",
    "\n",
    "---\n",
    "\n",
    "### 🤔 でも、AIの頭が悪くないですか？ (The Problem)\n",
    "今のAI（Bigramモデル）は、単語の綴り（スペル）は覚えたようですが、会話の内容はまだ支離滅裂です。\n",
    "\n",
    "**なぜでしょうか？**\n",
    "\n",
    "それは、このAIが **「金魚 (Goldfish)」** だからです。\n",
    "記憶力が「直前の1文字」しかありません。「いらっしゃい」と言うために、「い」だけを見て「ら」を予測しています。前の会話なんて忘れています。\n",
    "\n",
    "### 🚀 午後の予告：脳の移植手術 (Coming Up Next)\n",
    "お昼休憩のあと、このAIに **「脳の移植手術」** を行います。\n",
    "\n",
    "午後の部では、GoogleやOpenAIが採用している技術 **「Transformer (トランスフォーマー)」** を導入します。\n",
    "AIに「記憶力（文脈を読む力）」を与えると、会話がどう劇的に変わるのか...お楽しみに！\n",
    "\n",
    "では、お昼休みに入りましょう！🍜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321f6ff-1223-4abd-80cf-1545d3fc13ed",
   "metadata": {},
   "source": [
    "---\n",
    "# 🍜 頑固ラーメン屋のAIを作ろう (Build a Stubborn Ramen AI)\n",
    "\n",
    "---\n",
    "```text\n",
    " FFFFF   A   QQQQ      BBBB   OOO  TTTTT\n",
    " F      A A  Q  Q      B  B  O   O   T\n",
    " FFF   AAAAA Q  Q      BBBB  O   O   T\n",
    " F     A   A Q  Q      B  B  O   O   T\n",
    " F     A   A  QQ Q     BBBB   OOO    T\n",
    "```\n",
    "# 🚀 午後の部：AIの「脳」をアップグレードしよう (Level 2)\n",
    "\n",
    "午前のモデルは「直前の1文字」しか見ていませんでした（金魚の記憶力）。\n",
    "これでは「ラーメン」と言いたいのに、「ラ」の次に「ク」が来て「ラクダ」になってしまうかもしれません。\n",
    "\n",
    "午後は、GoogleやOpenAIが使っている技術**「Transformer (トランスフォーマー)」**を導入します。\n",
    "\n",
    "### 変わること (Changes)\n",
    "1. **Self-Attention (注意機構)**: AIが「過去の会話」を振り返るようになります。\n",
    "2. **Context (文脈)**: 「いらっしゃい」と言われたら「ませ」と返す、といった長い繋がりを理解します。\n",
    "3. **Complexity (複雑さ)**: コードが長くなりますが、やることは同じ「次に来る文字の予測」です。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff7d4b-1ef8-43ce-84f9-436c357d58f2",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ ステップ1 (午後)：設定の更新 (Update Settings)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb07922-bce0-4a02-a729-afcf3029a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 脳のスペックを上げます\n",
    "batch_size = 32  # 一度に処理する量\n",
    "block_size = 32  # 記憶力 (午前は8文字でしたが、午後は32文字まで覚えます！)\n",
    "max_iters = 3000 # 学習回数\n",
    "learning_rate = 1e-3\n",
    "n_embd = 64      # ベクトルの次元数\n",
    "n_head = 4       # ヘッド数\n",
    "n_layer = 4      # レイヤー数\n",
    "dropout = 0.0    # ドロップアウト率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5a757-b20f-4b16-a9c2-4adf77ca1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# データの読み込み方も、長い記憶力に合わせて更新します\n",
    "# ------------------------------------------------------------------------------\n",
    "def get_batch(split):\n",
    "    # block_size (=32) を使うように変更\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "print(f\"設定完了！記憶力が {block_size} 文字にアップグレードされました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf1b64-3546-49f1-9740-0be32f240409",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ ステップ2 (午後)：GPT トランスフォーマー (新しい脳)\n",
    "# ==============================================================================\n",
    "# 警告: ここはコードが長いですが、コピー＆ペーストでOKです！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d801d3-0160-41bc-a166-7231daec1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" アテンション・ヘッド：過去の重要な情報を探す機能 \"\"\"\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   \n",
    "        q = self.query(x) \n",
    "        # ここで過去の文字との関連性を計算しています (Search)\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" 複数のヘッドで同時に考える機能 \"\"\"\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" 考えたことを整理する機能 \"\"\"\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" これらをひとまとめにしたブロック \"\"\"\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eabc11-b9c6-4d23-995e-31534230b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# これが新しい AI モデルです (GPT)\n",
    "# ==============================================================================\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 文字をベクトルに変換\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        # 「文字の位置」を覚える機能 (Position Embedding)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        # トランスフォーマーのブロックを積み重ねる\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) \n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx) \n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device)) \n",
    "        x = tok_emb + pos_emb \n",
    "        x = self.blocks(x) \n",
    "        x = self.ln_f(x) \n",
    "        logits = self.lm_head(x) \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # 過去 block_size 分の文字だけを見るように切り取る\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "print(\"GPTモデル（トランスフォーマー）の定義完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e8bedc-b535-4cce-b191-967d59f595d7",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ ステップ3 (午後)：新しい脳でトレーニング\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9714ab7-66a7-45d2-b35c-0e7d83754f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しい GPTモデルを初期化\n",
    "model = GPTLanguageModel()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"レベルアップした脳で {max_iters} 回の学習を開始します...\")\n",
    "print(\"ヒント: Lossが 2.0 を切ると、かなり賢くなります。\")\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # 午後用のデータを取得 (32文字の記憶)\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # 学習ステップ (午前と同じことを繰り返します)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % 500 == 0:\n",
    "        print(f\"回数: {iter}, 誤差(Loss): {loss.item():.4f}\")\n",
    "\n",
    "print(f\"学習完了！ 最終Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614e02e-66bf-431e-8379-57043dc20318",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# ✅ ステップ4 (午後)：完成したAIと話そう\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd7da7-29c9-4dec-8b12-6be7792c8105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# チャット関数 (午前と同じですが、今の賢い model を使います)\n",
    "def chat_with_smart_ai(start_text):\n",
    "    try:\n",
    "        context = torch.tensor([encode(start_text)], dtype=torch.long)\n",
    "    except KeyError:\n",
    "        print(\"エラー: 学習データにない文字が含まれています。\")\n",
    "        return\n",
    "\n",
    "    print(f\"あなた: {start_text}\", end=\"\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # 生成 (午後は少し長く喋らせてみましょう)\n",
    "    generated_indices = model.generate(context, max_new_tokens=100)[0].tolist()\n",
    "    \n",
    "    full_text = decode(generated_indices)\n",
    "    ai_response = full_text[len(start_text):]\n",
    "    \n",
    "    print(f\"AI店長(GPT): {ai_response}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"--- 頑固ラーメンGPT ---\")\n",
    "print(\"終了するには「終了」と入力してください\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"入力してください (例: 客：おすすめは？) >> \")\n",
    "    if user_input == \"終了\" or user_input == \"exit\":\n",
    "        break\n",
    "    \n",
    "    chat_with_smart_ai(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4eb8c-2a56-45a5-bf4e-e155cf644093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def chat_with_smart_ai2(start_text):\n",
    "    try:\n",
    "        context = torch.tensor([encode(start_text)], dtype=torch.long)\n",
    "    except KeyError:\n",
    "        print(\"エラー: 学習データにない文字が含まれています。\")\n",
    "        return\n",
    "\n",
    "    print(f\"あなた: {start_text}\", end=\"\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # 生成 (Generate)\n",
    "    generated_indices = model.generate(context, max_new_tokens=100)[0].tolist()\n",
    "    full_text = decode(generated_indices)\n",
    "    \n",
    "    # 入力した部分を取り除く\n",
    "    ai_response = full_text[len(start_text):]\n",
    "    \n",
    "    # =================================================================\n",
    "    # ✂️ 追加コード (The Cut-off Logic)\n",
    "    # AIが勝手に「客：」のセリフを書き始めたら、そこで切り落とします\n",
    "    # =================================================================\n",
    "    if \"客：\" in ai_response:\n",
    "        ai_response = ai_response.split(\"客：\")[0]\n",
    "    \n",
    "    print(f\"AI店長(GPT): {ai_response}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"--- 頑固ラーメンGPT ---\")\n",
    "print(\"終了するには「終了」と入力してください\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"入力してください (例: 客：おすすめは？) >> \")\n",
    "    if user_input == \"終了\" or user_input == \"exit\":\n",
    "        break\n",
    "    \n",
    "    chat_with_smart_ai2(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea1030-ea0b-4495-9268-e5a9f3bba057",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "# 🎓 ワークショップ完了：卒業おめでとうございます！\n",
    "\n",
    "長い一日、お疲れ様でした！\n",
    "皆さんは今日、Pythonを使って「何も知らない状態」から「文脈を読むAI」への進化を目撃しました。\n",
    "\n",
    "### 🏆 今日の成果 (Summary)\n",
    "\n",
    "| | 午前：Bigram (金魚) | 午後：Transformer (GPT) |\n",
    "| :--- | :--- | :--- |\n",
    "| **記憶力** | 直前の1文字だけ | 過去32文字 (文脈) |\n",
    "| **Loss (誤差)** | 2.5 付近で限界 | **1.5 以下** に激減！ |\n",
    "| **会話能力** | 宇宙語・支離滅裂 | 「塩ラーメン」を文脈で理解 |\n",
    "| **正体** | 次の文字のサイコロ | **高度な次の文字予測機** |\n",
    "\n",
    "### 💡 最後に：AIが「勝手に客のセリフ」を喋った理由\n",
    "最後のチャット実験で、AIが勝手に「客：水ください」と続きを書き始めませんでしたか？\n",
    "\n",
    "これが **LLM (大規模言語モデル)** の本質です。\n",
    "AIは「質問に答えるロボット」ではなく、 **「与えられたテキストの続きをひたすら書く小説家」** なのです。\n",
    "\n",
    "私たちが普段使っている ChatGPT などは、AIが勝手に続きを書かないように、人間がプログラムで「ストップ！」と命令しているだけなんですね。\n",
    "\n",
    "---\n",
    "### 🏠 宿題 (Next Steps)\n",
    "このノートブックはあなたのものです。家に帰って以下を試してみてください。\n",
    "1. **データ量**: ラーメン屋のテキストをもっと長く書いてみる。\n",
    "2. **別の性格**: 関西弁のデータに変えてみる。\n",
    "3. **脳の拡大**: `n_layer` や `n_head` の数字を大きくしてみる（PCが重くなりますが賢くなります）。\n",
    "\n",
    "本日はありがとうございました！🍜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbfadc-e480-4f47-a903-80f65ce2d93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
