{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65eed6-bb92-48af-897f-ce2a19dce760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ---------------------------------------------------------------------------------\n",
    "#  FFFFF   A   QQQQ      BBBB   OOO  TTTTT\n",
    "#  F      A A  Q  Q      B  B  O   O   T\n",
    "#  FFF   AAAAA Q  Q      BBBB  O   O   T\n",
    "#  F     A   A Q  Q      B  B  O   O   T\n",
    "#  F     A   A  QQ Q     BBBB   OOO    T\n",
    "# \n",
    "#  「初めてのFAQ言語モデル構築」ラボへようこそ！\n",
    "#\n",
    "#  このノートブックでは、完全な言語モデルをゼロから構築し、\n",
    "#  簡単なFAQチャットボットとしてトレーニングします。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "# =================================================================================\n",
    "#  ✅ パート1：セットアップとデータ準備\n",
    "# =================================================================================\n",
    "#\n",
    "#  まず、データを準備する必要があります。AIモデルの「燃料」は、質問と回答を含む\n",
    "#  テキストファイルです。また、必要なライブラリもインポートします。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076a6ea-2930-4ed7-bae9-f13d45e7add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ1.1：ライブラリのインポート ---\n",
    "# ニューラルネットワークの構築にはPyTorchを、UIにはipywidgetsを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fa996-a29e-48c8-a697-7b8b971f78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb65c3c-61aa-4fa7-83c9-53484180b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ1.2：データセットの作成と読み込み ---\n",
    "# 実際のワークショップでは、受講者にプロンプトテンプレートを使用してこのテキストファイルを\n",
    "# 生成させ、「faq.txt」として保存してもらいます。この例では、ここで定義します。\n",
    "#\n",
    "# ----------------- あなたのFAQデータをここに記述 -----------------\n",
    "#\n",
    "#  手順：\n",
    "#  1. ワークショップで提供されたプロンプトテンプレートを使用して、FAQコンテンツを生成します。\n",
    "#  2. 生成されたテキストを以下の三重引用符で囲まれた文字列に貼り付けます。\n",
    "#  3. ファイルがこのノートブックと同じディレクトリに保存されていることを確認してください。\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea87c4b-cdd8-4dea-bf85-14220eb8ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_text = \"\"\"\n",
    "Q: What are the store hours?\n",
    "A: Our store is open from 9 AM to 8 PM, Monday to Saturday.\n",
    "\n",
    "Q: What is the return policy?\n",
    "A: You can return any item within 30 days of purchase with a valid receipt.\n",
    "\n",
    "Q: Do you offer gift wrapping?\n",
    "A: Yes, we offer complimentary gift wrapping for all in-store purchases.\n",
    "\n",
    "Q: Where are you located?\n",
    "A: We are located at 123 Main Street, Anytown, USA.\n",
    "\n",
    "Q: Can I place an order online?\n",
    "A: Yes, you can place an order through our website at www.example-store.com.\n",
    "\n",
    "Q: What payment methods do you accept?\n",
    "A: We accept all major credit cards, debit cards, and mobile payments.\n",
    "\n",
    "Q: Is there parking available?\n",
    "A: Yes, there is a free parking lot available for all our customers behind the store.\n",
    "\n",
    "Q: Do you have a loyalty program?\n",
    "A: Yes, you can sign up for our free loyalty program to earn points on every purchase.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a963b8b-370f-4752-806d-ed08b6d182a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ1.2：ファイルからのデータセットの読み込み ---\n",
    "# 受講者が作成した`faq.txt`ファイルを読み込みます。\n",
    "#`faq.txt`ファイルからデータを読み込みます。\n",
    "# ↓ この部分をコメントアウトまたは削除します ↓\n",
    "#with open('faq.txt', 'r', encoding='utf-8') as f:\n",
    "#    faq_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d34584-899f-4ed3-874c-dcf154261656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "\n",
    "# 扱っているデータを見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da0ba4-adfc-4638-8294-b905499e07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Sample of our dataset ---\")\n",
    "print(faq_text[:200])\n",
    "print(\"-----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e45615-9ac4-4b36-899f-b8991cd52e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ1.3：語彙の作成 ---\n",
    "# 私たちのモデルは文字を理解できません。数字しか理解できません。そのため、「語彙」を作成し、\n",
    "# 一意の各文字をそれぞれの一意の整数にマッピングする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a89fe2-6e59-415d-ac1e-3ac80f4cd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(faq_text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"Our vocabulary contains {vocab_size} unique characters.\")\n",
    "print(f\"Vocabulary: {''.join(chars)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b149d-13da-4c1d-8761-1e3e5255bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字から整数へ（stoi）、整数から文字へ（itos）のマッピングを作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab354b-1a46-42a2-ac55-75dc04bbe58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5bbbe-7eb9-43eb-b1c5-88c1caff8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンコードおよびデコード関数を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265ebef-af5d-4671-94c6-f2b98db2e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s if c in stoi] # エンコーダー：文字列を受け取り、整数のリストを出力します\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # デコーダー：整数のリストを受け取り、文字列を出力します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36275910-b457-4cb6-8ad5-852c81bfeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストしてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5781f-cd99-48ac-9e76-5227ce2e8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"store hours\"\n",
    "encoded_string = encode(test_string)\n",
    "decoded_string = decode(encoded_string)\n",
    "print(f\"Original: '{test_string}'\")\n",
    "print(f\"Encoded: {encoded_string}\")\n",
    "print(f\"Decoded: '{decoded_string}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f92b8-0b6e-43a6-b821-c0ff4a16a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ1.4：データセットのトークン化 ---\n",
    "# これで、テキストデータセット全体を単一の数値シーケンスに変換します。\n",
    "# PyTorchは、「テンソル」というデータ構造を使用して数値を扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd23190-855e-466e-b651-da3d039ff7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(faq_text), dtype=torch.long)\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"First 100 tokens: {data[:100]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e415e84-2406-418a-9a0f-99c53a7e1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ1.5：データをトレーニングセットと検証セットに分割する ---\n",
    "# データの大部分をモデルのトレーニング（学習）に使用し、一部を検証\n",
    "# （単に暗記するだけでなく、正しく学習しているかを確認するため）に使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2669e81-eb33-451f-9cc5-e3454ae6c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data)) # 最初の90%をトレーニング、残りを検証用とします\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fe2ac-1ab8-457a-b678-0d7e57f0d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "#  ✅ パート2：コンテキストとバッチの理解\n",
    "# =================================================================================\n",
    "#\n",
    "#  言語モデルは、テキストの塊（コンテキスト）を見て、次の文字を\n",
    "#  予測しようとすることで学習します。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff173b-6526-45ab-9940-93d56a67ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ2.1：コンテキストサイズの定義 ---\n",
    "# `block_size`は、モデルが見ることができるコンテキストの最大長です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87eeb5b-dd33-4795-b81f-e404abcb6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 64\n",
    "print(f\"A single training example (x): {train_data[:block_size].tolist()}\")\n",
    "print(f\"The target for each character in x (y): {train_data[1:block_size+1].tolist()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fe381-0539-4d90-8395-f1c6bb550777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ2.2：バッチ作成関数の定義 ---\n",
    "# モデルを「バッチ」と呼ばれる小さなランダムなデータの塊でトレーニングします。\n",
    "# これにより、トレーニングプロセスがより効率的で安定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fa754-1ff8-4406-8106-0e76827812fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # 並行して処理する独立したシーケンスの数は？\n",
    "\n",
    "def get_batch(split):\n",
    "    # 入力xとターゲットyの小さなデータバッチを生成します\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8bd36-bc65-47ac-95e3-a3c522c1c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルバッチを見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa0264-f3f9-4fbc-828b-8413f4ef22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print(\"--- Sample Batch ---\")\n",
    "print(f\"Inputs (xb) shape: {xb.shape}\")\n",
    "print(f\"Targets (yb) shape: {yb.shape}\")\n",
    "print(\"--------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131161b-ece5-4fa7-9fc7-22b42acd1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "#  ✅ パート3：Transformerモデルの構築（ゼロから！）\n",
    "# =================================================================================\n",
    "#\n",
    "#  ここが最もエキサイティングな部分です！GPTのようなモデルの基盤である\n",
    "#  Transformerアーキテクチャのコアコンポーネントを構築します。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd721ff-cd0b-4a8e-8485-9567511b2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ハイパーパラメータ ---\n",
    "# これらはモデルの設定です。後でこれらを試すことができます！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2b1ed-188e-47d5-bcbf-d85875c7f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 128       # 各文字の埋め込みサイズ\n",
    "n_head = 4         # アテンションヘッドの数\n",
    "n_layer = 4        # トランスフォーマーブロックの数\n",
    "dropout = 0.2      # 過学習を防ぐための正則化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ba57d-e680-4450-82bf-1efb72a24260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "\n",
    "# --- ステップ3.1：自己アテンションヘッド ---\n",
    "# これは基本的なコンポーネントです。「アテンションヘッド」により、モデルはコンテキスト内の\n",
    "# 他の文字を見て、次の文字を予測するために最も重要な文字を決定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af168d-af37-442d-887d-fe10fb075ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" 自己アテンションの1つのヘッド \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # アテンションスコア（「親和性」）を計算します\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # 値の加重集計を実行します\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d3b51-5c8c-42b7-8b18-ae1f95c2e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ3.2：マルチヘッドアテンション ---\n",
    "# モデルをより強力にするために、複数のアテンションヘッドを並行して使用し、\n",
    "# その結果を組み合わせます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f315e9d-1e5f-48df-b6d7-13de0821d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" 並列のマルチヘッド自己アテンション \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422d1dd-134f-4ac6-a081-64417ef7ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ3.3：フィードフォワードネットワーク ---\n",
    "# アテンションメカニズムの後、各文字の表現は、収集された情報を処理するために\n",
    "# 単純なニューラルネットワークを通過します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acae8a6-ff91-4d8c-abdb-0208a79861c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\" 単純な線形層とそれに続く非線形性 \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb1228-8083-4161-8ba8-acebe903435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ3.4：トランスフォーマーブロック ---\n",
    "# これで、アテンションとフィードフォワードコンポーネントを単一の「トランスフォーマーブロック」に\n",
    "# 組み合わせます。実際のLLMは、これらのブロックを多数積み重ねたものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975c241-8762-4a14-814d-b5edba26877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" トランスフォーマーブロック：通信とその後の計算 \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fea4cf-c1f0-447d-b946-54665c936ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ3.5：完全な言語モデル ---\n",
    "# 最後に、すべてを組み立てて完全な言語モデルを作成します！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d62fc4-3a88-4026-b4a4-041e0406b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 各トークンは、ルックアップテーブルから次のトークンのロジットを直接読み取ります\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # 最終レイヤーノルム\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idxとtargetsは両方とも整数の(B,T)テンソルです\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idxは現在のコンテキストにおけるインデックスの(B, T)配列です\n",
    "        for _ in range(max_new_tokens):\n",
    "            # idxを最後のblock_sizeトークンに切り詰めます\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # 予測を取得します\n",
    "            logits, loss = self(idx_cond)\n",
    "            # 最後のタイムステップのみに焦点を合わせます\n",
    "            logits = logits[:, -1, :] # (B, C)になります\n",
    "            # ソフトマックスを適用して確率を取得します\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # 分布からサンプリングします\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # サンプリングされたインデックスを実行中のシーケンスに追加します\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abb242-eb94-4911-b5dd-d445ff7c4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのインスタンスを作成しましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d6cf5-8f87-4e50-a782-c754ed4012a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel()\n",
    "print(\"Language Model created successfully!\")\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "#  ✅ パート4：モデルのトレーニング\n",
    "# =================================================================================\n",
    "#\n",
    "#  これで、データをモデルに供給して学習させます。このプロセスでは、モデルにデータの\n",
    "#  バッチを表示し、その予測がどれだけ「間違っている」か（「損失」）を計算し、\n",
    "#  内部パラメータをわずかに調整して改善します。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a398e-d0c2-4840-bd72-97540416abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ4.1：オプティマイザの作成 ---\n",
    "# オプティマイザは、モデルのパラメータを調整するアルゴリズムです。\n",
    "# AdamWは人気があり効果的な選択肢です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9270b7-ffad-445b-a10d-c739b7b7ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a243818-f8b6-4dbd-9b46-38413e013747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ4.2：トレーニングループ ---\n",
    "# このループは、設定されたステップ数だけ実行されます。各ステップで、データのバッチを取得し、\n",
    "# モデルに予測を求め、モデルを更新します。\n",
    "#\n",
    "# 注：これには数分かかります！\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42583daf-eae9-4f1a-abfe-c2884f2af016",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 5000 # トレーニングステップの数は？（多いほど良いですが、時間がかかります）\n",
    "eval_interval = 500 # 検証損失をチェックする頻度は？\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # 時々、トレーニングセットと検証セットの損失を評価します\n",
    "    if iter % eval_interval == 0:\n",
    "        # コードの繰り返しを避けるために、損失を推定する関数を作成します\n",
    "        @torch.no_grad()\n",
    "        def estimate_loss():\n",
    "            out = {}\n",
    "            model.eval()\n",
    "            for split in ['train', 'val']:\n",
    "                losses = torch.zeros(200)\n",
    "                for k in range(200):\n",
    "                    X, Y = get_batch(split)\n",
    "                    logits, loss = model(X, Y)\n",
    "                    losses[k] = loss.item()\n",
    "                out[split] = losses.mean()\n",
    "            model.train()\n",
    "            return out\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # データのバッチをサンプリングします\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # 損失を評価します\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"--- Training Complete! ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd377c-2714-4a5b-878c-8084b4c304c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "#  ✅ パート5：FAQボットで回答を生成！\n",
    "# =================================================================================\n",
    "#\n",
    "#  いよいよ本番です！トレーニング済みのモデルを使って質問に答えさせましょう。\n",
    "#  「プロンプト」として質問を与え、モデルが何を生成するか見てみましょう。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# --- ステップ5.1：生成関数 ---\n",
    "# ボットと対話するための簡単な関数を書きましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd69cf9-5c8a-43ce-b9a2-55239904792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bot(question):\n",
    "    \"\"\"\n",
    "    質問文字列を受け取り、モデルを使って回答を生成します。\n",
    "    \"\"\"\n",
    "    # モデル用のプロンプトを準備します\n",
    "    prompt = f\"Q: {question}\\nA:\"\n",
    "    print(prompt, end='') # プロンプトを改行なしで表示します\n",
    "\n",
    "    # プロンプトをエンコードしてテンソルを作成します\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    # 回答を生成します\n",
    "    generated_output = model.generate(context, max_new_tokens=100)[0].tolist()\n",
    "\n",
    "    # 結果をデコードして表示します\n",
    "    answer = decode(generated_output)\n",
    "    # 生成された部分だけが必要なので、回答がどこから始まるかを見つけます\n",
    "    answer_part = answer[len(prompt):]\n",
    "    print(answer_part.split('Q:')[0].split('\\n\\n')[0]) # 新しい質問が始まったら表示を停止します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60d469-86ac-4a77-a802-c9bdb68541f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ5.2：テストしてみましょう！ ---\n",
    "# これがデータベースではないことを証明するために、トレーニングデータとは\n",
    "# 少し異なる質問をしてみましょう。これにより、モデルが学習したパターンから\n",
    "# 一般化する能力をテストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e02ae-0b20-4e35-a5cd-6fc34b08f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Ask the FAQ Bot ---\")\n",
    "ask_bot(\"what are the store hours?\") # 小文字を使用\n",
    "ask_bot(\"do you offer gift wrapping\") # 小文字で、疑問符なし\n",
    "ask_bot(\"return policy?\") # より曖昧で部分的な質問\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d086d1e-46c2-4a3a-b366-8aef9cf9688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "#  ✅ パート6：インタラクティブなFAQボット！\n",
    "# =================================================================================\n",
    "#\n",
    "#  それでは、このノートブック上で簡単なユーザーインターフェースを作成し、\n",
    "#  ボットと対話できるようにしましょう。\n",
    "#\n",
    "# ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1377ad1-fe66-47c8-bea0-f9e122422015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ6.1：ユーザーインターフェースの構築 ---\n",
    "# `ipywidgets`ライブラリを使用して、テキストボックスとボタンを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3c18c-43a6-419c-82db-51b07b873f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ウィジェットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29450c95-882e-4322-8798-6ef9ed2e8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_input = widgets.Text(\n",
    "    value='What are the store hours?',\n",
    "    placeholder='Type your question here',\n",
    "    description='Question:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Ask Bot',\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to get an answer',\n",
    "    icon='question-circle'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990715dc-d9bc-4088-9130-7e80af6091d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ6.2：ボタンクリックアクションの定義 ---\n",
    "# この関数は、「ボットに質問」ボタンをクリックするたびに実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd63012-ce22-411d-85b9-000a2be96f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output() # 前の回答をクリア\n",
    "        question = question_input.value\n",
    "\n",
    "        # モデル用のプロンプトを準備\n",
    "        prompt = f\"Q: {question}\\nA:\"\n",
    "        print(prompt, end='')\n",
    "\n",
    "        # プロンプトをエンコードしてテンソルを作成\n",
    "        context = torch.tensor(encode(prompt), dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        # 回答を生成\n",
    "        generated_output = model.generate(context, max_new_tokens=100)[0].tolist()\n",
    "\n",
    "        # 結果をデコードして表示\n",
    "        answer = decode(generated_output)\n",
    "        answer_part = answer[len(prompt):]\n",
    "        # 新しい質問を開始したり、ループに陥ったりした場合は、印刷を停止します\n",
    "        final_answer = answer_part.split('Q:')[0].split('\\n\\n')[0]\n",
    "        print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e95a8-4f57-48d1-8ae4-7c55479b5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボタンを関数にリンクします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d642c96-6206-411d-8cff-8e83fa6890f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b925b-23a2-4b74-9d4e-3ec73ae3bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ステップ6.3：ボットを表示！ ---\n",
    "# UI要素を表示します。質問を入力してボタンをクリックしてください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27157728-8b13-4adb-993a-a0231559b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Interactive FAQ Bot ---\")\n",
    "display(question_input, submit_button, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc3d1f-f3cb-459b-b2a6-6194256ae39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 最終的な考察と次のステップ ---\n",
    "#\n",
    "# おめでとうございます！インタラクティブなUIを備えた言語モデルを構築し、デプロイしました。\n",
    "#\n",
    "# これは「シード」プロジェクトです。完璧ではありませんが、コアコンセプトを実証しています。\n",
    "# 改善するためには、次のことができます：\n",
    "#   1. faq.txtファイルにさらにデータを追加する。\n",
    "#   2. トレーニングの反復回数を増やす（`max_iters`を増やす）。\n",
    "#   3. ハイパーパラメータ（例：`n_embd`、`n_head`、`n_layer`）を試す。\n",
    "#   4. UIとエラーハンドリングを改善する。\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
